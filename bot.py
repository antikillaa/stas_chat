import os
import re
import asyncio
from dotenv import load_dotenv

from aiogram import Bot, Dispatcher, types, F
from aiogram.filters import Command
from openai import OpenAI

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ ---
load_dotenv()
TG_TOKEN = os.getenv("TG_TOKEN")
HF_TOKEN = os.getenv("HF_TOKEN")

if not TG_TOKEN:
    raise RuntimeError("TG_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env")
if not HF_TOKEN:
    raise RuntimeError("HF_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env")

bot = Bot(TG_TOKEN)
dp = Dispatcher()

# --- LM Studio / Local ---
client = OpenAI(
    base_url="http://127.0.0.1:1234/v1",
    api_key="lm-studio"  # LM Studio –Ω–µ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–ª—é—á
)

# --- Persona ---
with open("persona.txt", "r", encoding="utf-8") as f:
    persona = f.read()

# --- –ü–∞–º—è—Ç—å —á–∞—Ç–∞ ---
chat_memory = {}
MAX_HISTORY = 20

def update_history(chat_id: int, role: str, text: str):
    if chat_id not in chat_memory:
        chat_memory[chat_id] = {"history": [], "mode": "stylish"}
    chat_memory[chat_id]["history"].append({"role": role, "content": text})
    chat_memory[chat_id]["history"] = chat_memory[chat_id]["history"][-MAX_HISTORY:]

# --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ ---
async def generate_reply(chat_id: int, user_msg: str) -> str:
    mode = chat_memory.get(chat_id, {}).get("mode", "stylish")

    system_prompt = (
        f"–¢—ã ‚Äî —ç—Ç–æ —è. –û–±—â–∞–π—Å—è –≤ –º–æ–µ–º —Å—Ç–∏–ª–µ.\n"
        f"–ú–æ–π —Å—Ç–∏–ª—å:\n{persona}\n"
    )
    if mode == "stylish":
        system_prompt += "–û—Ç–≤–µ—á–∞–π –∫–æ—Ä–æ—Ç–∫–æ, –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ –∫–∞–∫ —è –±—ã —Å–∫–∞–∑–∞–ª."
    else:
        system_prompt += "–û—Ç–≤–µ—á–∞–π –ø–æ–¥—Ä–æ–±–Ω–æ, —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç–æ –∏ –æ–±—ä—è—Å–Ω—è–π –≤—Å–µ –¥–µ—Ç–∞–ª–∏."

    messages = [{"role": "system", "content": system_prompt}]

    if chat_id in chat_memory:
        messages.extend(chat_memory[chat_id]["history"])

    messages.append({"role": "user", "content": user_msg})

    response = client.chat.completions.create(
        model="openai/gpt-oss-20b",  # –∏–ª–∏ –ª—é–±–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ LM Studio
        messages=messages,
    )

    assistant_reply = response.choices[0].message.content
    assistant_reply = re.sub(r"<think>.*?</think>", "", assistant_reply, flags=re.DOTALL).strip()

    update_history(chat_id, "assistant", assistant_reply)
    return assistant_reply

# --- –ò–º—è –±–æ—Ç–∞ ---
bot_names = ["–°—Ç–∞—Å—è–Ω", "–°—Ç–∞—Å—è–Ω–∞", "–°—Ç–∞—Å—è–Ω—É", "–°—Ç–∞—Å—è–Ω–µ", "–°—Ç–∞—Å—è–Ω–æ–º", "–°—Ç–∞—Å—è–Ω–µ"]

# --- –°–ø–∏—Å–æ–∫ –ø–æ—Ö–≤–∞–ª ---
import random

PRAISES = [
    "–û, –±—Ä–∞—Ç, –º–æ–ª–æ–¥–µ—Ü üëç",
    "–¢–∞–∫ –¥–µ—Ä–∂–∞—Ç—å, –∫—Ä–∞—Å–∞–≤—á–∏–∫ üí™",
    "–ö—Ä–∞—Å–∏–≤–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å üòé",
    "–í–æ—Ç —ç—Ç–æ —É—Ä–æ–≤–µ–Ω—å üëè",
    "–ë—Ä–∞—Ç, –æ–≥–æ–Ω—å üî•",
    "–¢—ã –ø—Ä—è–º –Ω–∞ —Å—Ç–∏–ª–µ üòè",
    "–ù—É —Ç—ã –∑–∞–≥–Ω—É–ª, –∫—Ä—É—Ç–æ üëå",
    "–ë—Ä–∞—Ç, –∑–∞—á—ë—Ç üëä",
    "–°–∫–∏–Ω—å—Ç–µ —Ñ–æ—Ç–æ —á–ª–µ–Ω–∞ üòè",
]

POSITIVE_KEYWORDS = [
    "—Å–¥–µ–ª–∞–ª", "—É—Å–ø–µ—Ö", "–≥–æ—Ç–æ–≤–æ", "–∫–ª–∞—Å—Å", "–ø–æ—Ñ–∏–∫—Å–∏–ª",
    "–æ—Ç–ª–∏—á–Ω–æ", "—Å—É–ø–µ—Ä", "–∑–∞—Ä–∞–±–æ—Ç–∞–ª–æ", "–ø–æ–ª—É—á–∏–ª–æ—Å—å"
]

BASE_CHANCE = 0.5


# --- –ö–æ–º–∞–Ω–¥—ã ---
@dp.message(Command("reset"))
async def reset_chat(msg: types.Message):
    chat_id = msg.chat.id
    chat_memory[chat_id] = {"history": [], "mode": "stylish"}
    await msg.answer("–ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ –æ—á–∏—â–µ–Ω–∞ ‚úÖ, —Ä–µ–∂–∏–º —Å–±—Ä–æ—à–µ–Ω –Ω–∞ 'stylish'.")

@dp.message(Command("mode"))
async def change_mode(msg: types.Message):
    chat_id = msg.chat.id
    parts = msg.text.split()
    if len(parts) < 2 or parts[1] not in ["stylish", "detailed"]:
        await msg.answer("–ò—Å–ø–æ–ª—å–∑—É–π: /mode stylish –∏–ª–∏ /mode detailed")
        return
    chat_memory.setdefault(chat_id, {"history": [], "mode": "stylish"})["mode"] = parts[1]
    await msg.answer(f"–†–µ–∂–∏–º –∏–∑–º–µ–Ω–µ–Ω –Ω–∞ '{parts[1]}' ‚úÖ")


# --- –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π ---
@dp.message()
async def handle_message(msg: types.Message):
    chat_id = msg.chat.id
    text = msg.text or ""
    mentioned = False
    me = await bot.get_me()

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø–æ—Ö–≤–∞–ª–∞ –∑–∞ –º–µ–¥–∏–∞
    if msg.photo or msg.video or msg.animation:
        if random.random() < BASE_CHANCE:
            await msg.answer(random.choice(PRAISES))

    # –õ–∏—á–Ω—ã–µ —á–∞—Ç—ã ‚Äî —Ä–µ–∞–≥–∏—Ä—É–µ—Ç –≤—Å–µ–≥–¥–∞
    if msg.chat.type == "private":
        mentioned = True
    else:
        # @—É–ø–æ–º–∏–Ω–∞–Ω–∏–µ
        if msg.entities:
            for ent in msg.entities:
                if ent.type == "mention":
                    mention_text = text[ent.offset: ent.offset + ent.length]
                    if mention_text.lower() == f"@{me.username.lower()}":
                        text = text.replace(mention_text, "").strip()
                        mentioned = True

        # –∏–º—è –≤ —Ç–µ–∫—Å—Ç–µ
        if not mentioned:
            clean = re.sub(r"[^\w\s]", "", text.lower())
            for name in bot_names:
                if name.lower() in clean.split():
                    text = re.sub(name, "", text, flags=re.IGNORECASE).strip()
                    mentioned = True
                    break

        # reply –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–æ—Ç–∞
        if not mentioned and msg.reply_to_message:
            if msg.reply_to_message.from_user.id == me.id:
                mentioned = True

    if not mentioned:
        return

    update_history(chat_id, "user", text)

    await bot.send_chat_action(chat_id, "typing")
    await asyncio.sleep(1)

    reply = await generate_reply(chat_id, text)
    await msg.answer(reply)


# --- –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ (polling) ---
async def main():
    print("Bot started (polling). LM Studio must be running on port 1234.")
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())